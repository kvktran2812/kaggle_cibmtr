{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6b1564-6879-403c-b888-0e15c49fca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lifelines.utils import concordance_index\n",
    "from metric import score\n",
    "from sdv.single_table import CTGANSynthesizer, CopulaGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f4d9f6-8ec2-42de-8557-2e65567cdcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and train the CTGAN model\n",
    "# ctgan = CTGANSynthesizer(\n",
    "#     metadata=metadata,\n",
    "#     embedding_dim=256,\n",
    "#     generator_dim=[512, 512],\n",
    "#     discriminator_dim=[512, 512],\n",
    "#     generator_lr=1e-4,\n",
    "#     discriminator_lr=1e-4,\n",
    "#     batch_size=1000,\n",
    "#     epochs=40,\n",
    "#     verbose=True,\n",
    "#     cuda=True,\n",
    "# )\n",
    "\n",
    "# efs_1_df = train[train[\"efs\"] == 1]\n",
    "# ctgan.fit(efs_1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb25a49-b2bb-406d-8ded-96ca4c528b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train.csv\"\n",
    "test_path = \"data/test.csv\"\n",
    "sample_path = \"data/sample_submission.csv\"\n",
    "data_dict_path = \"data/data_dictionary.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "data_dict_df = pd.read_csv(data_dict_path)\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "def transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df[time_col], df[event_col])\n",
    "    y = kmf.survival_function_at_times(df[time_col]).values\n",
    "    return y\n",
    "train[\"y\"] = transform_survival_probability(train, time_col='efs_time', event_col='efs')\n",
    "\n",
    "RMV = [\"ID\", \"efs\", \"efs_time\", \"y\"]\n",
    "FEATURES = [c for c in train.columns if not c in RMV]\n",
    "# print(f\"Total features: {len(FEATURES)} - {FEATURES}\")\n",
    "\n",
    "CATS = []\n",
    "NUMS = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype==\"object\":\n",
    "        CATS.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "    else:\n",
    "        NUMS.append(c)\n",
    "        train[c] = train[c].fillna(-1)\n",
    "        test[c] = test[c].fillna(-1)\n",
    "# print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n",
    "\n",
    "combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "#print(\"Combined data shape:\", combined.shape )\n",
    "\n",
    "# LABEL ENCODE CATEGORICAL FEATURES\n",
    "# print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\n",
    "for c in FEATURES:\n",
    "\n",
    "    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "    if c in CATS:\n",
    "        # print(f\"{c}, \",end=\"\")\n",
    "        combined[c],_ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "        \n",
    "    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "    else:\n",
    "        if combined[c].dtype==\"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype==\"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "    \n",
    "train = combined.iloc[:len(train)].copy()\n",
    "test = combined.iloc[len(train):].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4d29dc-525a-47ce-9055-30dce40db873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dri_score: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "psych_disturb: [0, 1, 2, 3]\n",
      "cyto_score: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "diabetes: [0, 1, 2, 3]\n",
      "hla_match_c_high: [-1.0, 0.0, 1.0, 2.0]\n",
      "hla_high_res_8: [-1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n",
      "tbi_status: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "arrhythmia: [0, 1, 2, 3]\n",
      "hla_low_res_6: [-1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "graft_type: [0, 1]\n",
      "vent_hist: [0, 1, 2]\n",
      "renal_issue: [0, 1, 2, 3]\n",
      "pulm_severe: [0, 1, 2, 3]\n",
      "prim_disease_hct: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "hla_high_res_6: [-1.0, 0.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "cmv_status: [0, 1, 2, 3, 4]\n",
      "hla_high_res_10: [-1.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "hla_match_dqb1_high: [-1.0, 0.0, 1.0, 2.0]\n",
      "tce_imm_match: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "hla_nmdp_6: [-1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "hla_match_c_low: [-1.0, 0.0, 1.0, 2.0]\n",
      "rituximab: [0, 1, 2]\n",
      "hla_match_drb1_low: [-1.0, 1.0, 2.0]\n",
      "hla_match_dqb1_low: [-1.0, 0.0, 1.0, 2.0]\n",
      "prod_type: [0, 1]\n",
      "cyto_score_detail: [0, 1, 2, 3, 4, 5]\n",
      "conditioning_intensity: [0, 1, 2, 3, 4, 5, 6]\n",
      "ethnicity: [0, 1, 2, 3]\n",
      "year_hct: [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
      "obesity: [0, 1, 2, 3]\n",
      "mrd_hct: [0, 1, 2]\n",
      "in_vivo_tcd: [0, 1, 2]\n",
      "tce_match: [0, 1, 2, 3, 4]\n",
      "hla_match_a_high: [-1.0, 0.0, 1.0, 2.0]\n",
      "hepatic_severe: [0, 1, 2, 3]\n",
      "prior_tumor: [0, 1, 2, 3]\n",
      "hla_match_b_low: [-1.0, 0.0, 1.0, 2.0]\n",
      "peptic_ulcer: [0, 1, 2, 3]\n",
      "hla_match_a_low: [-1.0, 0.0, 1.0, 2.0]\n",
      "gvhd_proph: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "rheum_issue: [0, 1, 2, 3]\n",
      "sex_match: [0, 1, 2, 3, 4]\n",
      "hla_match_b_high: [-1.0, 0.0, 1.0, 2.0]\n",
      "race_group: [0, 1, 2, 3, 4, 5]\n",
      "comorbidity_score: [-1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "karnofsky_score: [-1.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
      "hepatic_mild: [0, 1, 2, 3]\n",
      "tce_div_match: [0, 1, 2, 3, 4]\n",
      "donor_related: [0, 1, 2, 3]\n",
      "melphalan_dose: [0, 1, 2]\n",
      "hla_low_res_8: [-1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n",
      "cardiac: [0, 1, 2, 3]\n",
      "hla_match_drb1_high: [-1.0, 0.0, 1.0, 2.0]\n",
      "pulm_moderate: [0, 1, 2, 3]\n",
      "hla_low_res_10: [-1.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "efs: [0.0, 1.0]\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for col in train.columns:\n",
    "    if train[col].dtype != \"object\" and len(train[col].unique()) <= 20:\n",
    "        count += 1\n",
    "        print(f\"{col}: {sorted(train[col].unique())}\")\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530db0be-ccbf-4bf2-a859-e143d6f79b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train = train.copy()\n",
    "augmented_train[\"donor_age\"] = augmented_train[\"donor_age\"] + np.random.uniform(-1, 1, size=len(augmented_train))\n",
    "augmented_train[\"age_at_hct\"] = augmented_train[\"age_at_hct\"] + np.random.uniform(-1, 1, size=len(augmented_train))\n",
    "augmented_train[\"year_hct\"] = augmented_train[\"age_at_hct\"] + np.random.choice([-1, 0, 1], size=len(augmented_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6694fbc7-0836-46aa-84b0-ab43dbfcf9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.concat([train, augmented_train])\n",
    "new_train = new_train.reset_index()\n",
    "new_train[\"ID\"] = new_train[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "232f5e08-a025-42b4-a9c4-fc0d7ab0d439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LightGBM version 4.5.0\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "print(\"Using LightGBM version\",lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bf1a971-4a83-4546-a169-e45b25cd503f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Fold 10\n"
     ]
    }
   ],
   "source": [
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_lgb = np.zeros(len(new_train))\n",
    "pred_lgb = np.zeros(len(test))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(new_train)):\n",
    "    print(f\"Fold {i+1}\")\n",
    "    \n",
    "    x_train = new_train.loc[train_index,FEATURES].copy()\n",
    "    y_train = new_train.loc[train_index,\"y\"]    \n",
    "    x_valid = new_train.loc[test_index,FEATURES].copy()\n",
    "    y_valid = new_train.loc[test_index,\"y\"]\n",
    "    x_test = test[FEATURES].copy()\n",
    "\n",
    "    model_lgb = LGBMRegressor(\n",
    "        device=\"gpu\", \n",
    "        max_depth=3, \n",
    "        colsample_bytree=0.4,  \n",
    "        subsample=0.9, \n",
    "        n_estimators=2500, \n",
    "        learning_rate=0.02, \n",
    "        objective=\"regression\", \n",
    "        verbose=-1, \n",
    "        early_stopping_rounds=25,\n",
    "    )\n",
    "    model_lgb.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "    )\n",
    "    \n",
    "    # INFER OOF\n",
    "    oof_lgb[test_index] = model_lgb.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_lgb += model_lgb.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_lgb /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c4a3d11-2a90-47d0-83b8-ad3ae9f46c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkvkh\\MyFolder\\projects\\kaggle\\cibmtr\\metric.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall CV for LightGBM KaplanMeier = 0.6869253456166916\n"
     ]
    }
   ],
   "source": [
    "y_true = new_train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = new_train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = oof_lgb\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for LightGBM KaplanMeier =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b18dcaf8-ef40-4812-8d74-4872c7c43e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkvkh\\MyFolder\\projects\\kaggle\\cibmtr\\metric.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall CV for LightGBM KaplanMeier = 0.707889399249549\n"
     ]
    }
   ],
   "source": [
    "prediction = model_lgb.predict(train[FEATURES])\n",
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = prediction\n",
    "m = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "print(f\"\\nOverall CV for LightGBM KaplanMeier =\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6fa6c8-30f3-4009-a4ff-d3ba9d0bd373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
